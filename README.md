# Adversarial Examples for Neural Network Interpretability

## The large scale results of attack methods against four famous feature-attribution methods
![alt text](https://github.com/adversarial-interpretability/adversarial-interpretability/blob/master/SaliencyMethodsComparison.png)

## Examples of targeted attack for semantically meaningful change in feature-importance
![alt text](https://github.com/adversarial-interpretability/adversarial-interpretability/blob/master/SemanticChange.png)

## Attack examples on Deep Taylor Decomposition
![alt text](https://github.com/adversarial-interpretability/adversarial-interpretability/blob/master/DTD_examples.png
)
